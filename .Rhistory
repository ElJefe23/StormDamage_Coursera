?gsub()
quiz4q2Data$GDP<-gsub(",","",quiz4q2Data$GDP)
quiz4q2Data$GDP
quiz4q2Data<-read.csv("./q4q2Data.csv")
quiz4q2Data$GDP<-as.character(quiz4q2Data$GDP)
quiz4q2Data$GDP<-gsub(",","",quiz4q2Data$GDP)
quiz4q2Data$GDP<-as.numeric(quiz4q2Data$GDP)
mean(quiz4q2Data$GDP)
quiz4q2Data$Country<-as.character(quiz4q2Data$Country)
grep("^United",quiz4q2Data$Country)
quiz4q2Data$Country
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile="q4q4Data.csv")
quiz4q4Data<-read.csv("./q4q4Data.csv")
?merge()
q4Merge<-merge(quiz4q4Data,quiz4q2Data,by.x="CountryCode",by.y="CountryCode")
names(q4Merge)
q4Merge[,10]
?grep()
grep("Fiscal year end",q4Merge[,10],value=TRUE)
q4Intermediate<-grep("Fiscal year end",q4Merge[,10],value=TRUE)
grep("June",q4Intermediate,value=TRUE)
q4Intermediate<-grep("June",q4Merge[,10],value=TRUE)
grep("June",q4Merge[,10],value=TRUE)
library(quantmod)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn
sampleTimes
?type()
typeof(sampleTimes)
typeof(sampleTimes)
?grep()
grep("2012",sampleTimes,value=TRUE)
all2012<-grep("2012",sampleTimes,value=TRUE)
all2012Days<-format(all2012,"%A %b %d")
dates2012<-as.Date(all2012,"%Y-%m-%d")
days2012<-weekdays(dates2012)
grep("Monday",days2012,value=TRUE)
?rexp()
qpr<-rexp(40.0.2)
qpr<-rexp(40,0.2)
mean(qpr)
qpr<-rexp(40,0.2)
mean(qpr)
mean(rexp(40,0.2))
mean(rexp(40,0.2))
mean(rexp(40,0.2))
mean(rexp(40,0.2))
?for
()
sd(rexp(40,0.2))
()
sd(rexp(40,0.2))
sd(rexp(40,0.2))
sd(rexp(40,0.2))
?rbinom
longdata=numeric(length=1000)
longdata=numeric(length=1500)
for {i in 1:1500} ()
for {i in 1:1500} { longdata[i]=mean(rexp(40,0.2))}
for (i in 1:1500) { longdata[i]=mean(rexp(40,0.2))}
mean(longdata)
sd(longdata)
5/sqrt(1500)
?hist
hist(longdata)
for (i in 1:1500) { longdata[i]=mean(rexp(40,0.2))}
mean(longdata)
sd(longdata)
5/sqrt(40)
hist(longdata)
sd(longdata)/sqrt(40)
longdata>(mean(longdata)+1.96*sd(longdata)/sqrt(40))
count(longdata>(mean(longdata)+1.96*sd(longdata)/sqrt(40)))
ul<-mean(longdata)+1.96*sd(longdata)
ll<-mean(longdata)-1.96*sd(longdata)
mean(ll<longdata & ul>longdata)
hist(longdata)
?hist()
hist(longdata,breaks=21)
abline(v=mean(longdata),col="blue",lwd=2)
abline(v=mean(longdata),col="red",lwd=4)
mean(ll<longdata & ul>longdata)
?array()
source('~/Course5Project1.R')
source('~/Course5Project1.R')
source('~/Course5Project1.R')
norm_comp
source('~/Course5Project1.R')
mean(ll<longdata & ul>longdata)
norm_comp
source('~/Course5Project1.R')
source('~/Course5Project1.R')
source('~/Course5Project1.R')
norm_comp
source('~/Course5Project1.R')
norm_comp
source('~/Project1Part2.R')
data(ToothGrowth)
source('~/Project1Part2.R')
summary(ToothGrowth)
source('~/Project1Part2.R')
data(ToothGrowth)
summary(ToothGrowth)
source('~/.active-rstudio-document')
source('~/Project1Part2.R')
t.test(withOJ$len,withVC$len)
withOJmedium<-subset(ToothGrowth, ToothGrowth$supp=="OJ" & ToothGrowth$dose==1.0)
source('~/Project1Part2.R')
t.test(withOJsmall$len,withOJmedium$len)
t.test(withOJmedium$len,withOJsmall$len)
t.test(withOJlarge$len,withOJmedium$len)
t.test(withVCmedium$len,withVCsmall$len)
t.test(withVClarge$len,withVCmedium$len)
t.test(withVClarge$len,withVCmedium$len)$confidence
t.test(withVClarge$len,withVCmedium$len)$conf
?power.t.test
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="one.sample")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="one.sample", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="two.sample", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.05,type="paired", alternative="one.sided")
power.t.test(power=0.9,delta=0.01,sd=0.04, sig.level=0.05,type="paired", alternative="one.sided")
power.t.test(n=100,delta=0.01,sd=0.04, sig.level=0.10,type="paired", alternative="one.sided")
?p.adjust
44-42.04+c(-1,1)*12*qt(0.975,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.95,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.99,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.97,574)*sqrt(2/288)
44-42.04+c(-1,1)*12*qt(0.995,574)*sqrt(2/288)
library(manipulate)
library(UsingR)
library(usingR)
install.packages("UsingR")
library(UsingR)
data(galton)
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.6, 1.2, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
?manipulate()
manipulate(myplot(beta), beta=slider(0.6,1.2))
?slider()
manipulate(myplot(beta), beta=slider(0.6,1.2,step=0.02))
detach("package:aplpack", unload=TRUE)
manipulate(myplot(beta), beta=manipulate.slider(0.6,1.2,step=0.02))
?lm()
lm((child-mean(child))~(parent-mean(parent)) -1, data=galton)
lm(I(child-mean(child))~I(parent-mean(parent)) -1, data=galton)
manipulate(myplot(beta), beta=manipulate::slider(0.6,1.2,step=0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), manipulate::beta = slider(0.6, 1.2, step = 0.02))
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = manipulate::slider(0.6, 1.2, step = 0.02))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x -1)
plot(x,y)
?plot
?lm
data(mtcars)
lm(mpg~weight, date=mtcars)
lm(mpg~weight, data=mtcars)
lm(mtcars$mpg ~ mtcars$weight)
lm(mtcars$mpg ~ mtcars$wt)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
mu <-mean(x)
sd<-stdev(x)
stdev<-sd(x)
x<-(x-mu)/sd
x<-(x-mu)/stdev
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(y~x)
mean(x)
library(AppliedPredictiveModeling)
install(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library("AppliedPredictiveModeling", lib.loc="~/R/win-library/3.1")
install.packages("caret")
library("caret", lib.loc="~/R/win-library/3.1")
data(AlzheimerDisease)
adData<-dataframe(diagnosis, predictors)
adData<-data.frame(diagnosis, predictors)
?createDataPartition()
trainIndex=createDataPartition(diagnosis, p=0.5, list=FALSE)
trainIndex=createDataPartition(diagnosis, p=0.5)
training=adData[trainIndex,]
trainIndex=createDataPartition(diagnosis, p=0.5, list=FALSE)
training=adData[trainIndex,]
data(concrete)
set.seed(975)
inTrain=createDataPartition(concrete$CompressiveStrength,p=3/4)
inTrain=createDataPartition(concrete$CompressiveStrength,p=3/4)[[1]]
training=concrete[inTrain,]
testing=concrete[-inTrain,]
summary(concrete)
?cut2()
library("Hmisc", lib.loc="~/R/win-library/3.1")
?cut2()
training$Cement<-cut2(training$Cement,m=7)
training$BlastFurnacesSlag<-cut2(training$BlastFurnacesSlag,m=7)
training$FlyAsh<-cut2(training$FlyAsh,m=7)
training$Water<-cut2(training$Water,m=7)
training$SuperPlasticizer<-cut2(training$SuperPlasticizer,m=7)
training$Superplasticizer<-cut2(training$Superplasticizer,m=7)
training$BlastFurnaceSlag<-cut2(training$BlastFurnaceSlag,m=7)
training$CourseAggregate<-cut2(training$CourseAggregate,m=7)
training$CoarseAggregate<-cut2(training$CoarseAggregate,m=7)
training$FineAggregate<-cut2(training$FineAggregate,m=7)
training$Age<-cut2(training$Age,m=7)
training$Age<-cut2(training$Age,m=7)
training=concrete[inTrain,]
training$Age<-cut2(training$Age,g=7)
training$FineAggregate<-cut2(training$FineAggregate,g=7)
training$CoarseAggregate<-cut2(training$CoarseAggregate,g=7)
training$BlastFurnaceSlag<-cut2(training$BlastFurnaceSlag,g=7)
training$Superplasticizer<-cut2(training$Superplasticizer,g=7)
training$FlyAsh<-cut2(training$FlyAsh,g=7)
training$Water<-cut2(training$Water,g=7)
training$Cement<-cut2(training$Cement,g=7)
?qplot()
?plot()
plot(training$CompressiveStrength)
qplot(training$CompressiveStrength, colour=training$Cement)
plot(training$CompressiveStrength, col=training$Cement)
plot(training$CompressiveStrength, col=training$BlastFurnaceSlag)
plot(training$CompressiveStrength, col=training$FlyAsh)
plot(training$CompressiveStrength, col=training$Water)
plot(training$CompressiveStrength, col=training$Age)
plot(training$CompressiveStrength, col=training$SuperPlasticizer)
plot(training$CompressiveStrength, col=training$Superplasticizer)
plot(training$CompressiveStrength, col=training$CoarseAggregate)
plot(training$CompressiveStrength, col=training$FineAggregate)
training=cement[inTrain,]
training=concrete[inTrain,]
qplot(training$Superplasticizer)
inTrainAD<-createDataPartition(adData$diagnosis, p=3/4)[[1]]
trainingAD=adData[inTrainAD,]
testingAD=adData[-inTrainAD,]
?preProcess()
summary(trainingAD)
trainingAD[,IL*]
trainingAD[,[IL*]]
trainingAD[,age]
trainingAD[,[age]]
trainingAD[,["age"]
trainingAD[,"age"]
trainingAD[,"IL*"]
row.labels(trainingAD)
row.label(trainingAD)
?grep()
trainingAD[,grep("IL*",names(trainingAD))]
grep("IL*",names(trainingAD))
names(trainingAD)
grep("IL_",names(trainingAD))
grep("\\IL_",names(trainingAD))
grep("\\bIL_",names(trainingAD))
subTrainAD<-trainingAD[,grep("\\bIL_",names(trainingAD))]
preProcess(subTrainAD,thresh=0.8)
preProcess(subTrainAD,thresh=0.8, verbose=TRUE)
preProcess(subTrainAD,method="pca", thresh=0.8, verbose=TRUE)
preProcess(subTrainAD,method="pca", thresh=0.8)
newTrain<-data.frame[trainingAD$diagnosis,subTrainAD]
newTrain<-colbind(trainingAD$diagnosis,subTrainAD)
newTrain<-cbind(trainingAD$diagnosis,subTrainAD)
?glm()
names(newTrain)[names(newTrain=="trainingAD$diagnosis")]<-"diagnosis"
names(newTrain)[1]<-"diagnosis"
glm(diagnosis~.,data=newTrain)
newTrain$diagnosis
train(diagnosis ~ ., date=newTrain, method="glm")
train(diagnosis ~ ., data=newTrain, method="glm")
lm(diagnosis ~ ., data=newTrain)
glm(diagnosis ~ ., data=newTrain)
newTrain[diagnosis="Impaired",diagnosis]
newTrain[diagnosis=="Impaired","diagnosis"]
newTrain[newtrain$diagnosis=="Impaired","diagnosis"]
newtrain$diagnosis
newTrain$diagnosis
newTrain[newTrain$diagnosis=="Impaired","diagnosis"]
train(diagnosis ~ ., data=newTrain, method="glm")
install.packages("e1071")
library("e1071", lib.loc="~/R/win-library/3.1")
train(diagnosis ~ ., data=newTrain, method="glm")
modFit1<-train(diagnosis ~ ., data=newTrain, method="glm")
summary(modFit1$finalModel)
?predict()
predict(modFit1,newdata=testingAD)
?confusion matrix
pred1<-predict(modFit1,newdata=testingAD)
xtab1<-table(pred1,testingAD$diagnosis)
confusionMatrix(xtab1)
preProc<-preProcess(newTrain[,-1], method="pca", thresh=0.8)
trainPC<-predict(preProc,newTrain[,-1])
modFit2<-train(newTrain$diagnosis ~ ., data=trainPC, method="glm")
pred2<-predict(modFit2,newdata=testingAD)
testPC<-predict(preProc,testingAD[,-1])
subTestAD<-testingAD[,grep("\\bIL_",names(testingAD))]
newTest<-cbind(testingAD$diagnosis,subTestAD)
names(newTest)[1]<-"diagnosis"
testPC<-predict(preProc,newTest[,-1])
pred2<-predict(modFit2,newdata=testPC)
xtab2<-table(pred2,testingAD$diagnosis)
confusionMatrix(xtab2)
library("AppliedPredictiveModeling", lib.loc="~/R/win-library/3.1")
library("caret", lib.loc="~/R/win-library/3.1")
library("e1071", lib.loc="~/R/win-library/3.1")
set.seed(3433)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
inTrain=createDataPartition(adDatadiagnosis,p=3/4)[[1]]
inTrain=createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain,]
subTestAD<-testing[,grep("\\bIL_",names(testing))]
subTrainAD<-training[,grep("\\bIL_",names(training))]
subTrainAD<-cbind(diagnosis,subTrainAD)
diagnosis
TrainAD<-cbind(diagnosis,subTrainAD)
trainDiagnosis<-diagnosis[inTrain]
testDiagnosis<-diagnosis[-inTrain]
TrainAD<-cbind(trainDiagnosis,subTrainAD)
testAD<-cbind(testDiagnosis,subTrainAD)
testAD<-cbind(testDiagnosis,subTestAD)
set.seed(3433)
data(AlzheimerDisease)
adData=data.frame(diagnosis,predictors)
adSubData<-adData[,grep("\\bIL_",names(adData))]
data(AlzheimerDisease)
set.seed(3433)
subPredictors<-predictors[,grep("\\bIL_",names(predictors))]
adData=data.frame(diagnosis,subPredictors)
inTrain=createDataPartition(adData$diagnosis,p=3/4)[[1]]
training=adData[inTrain,]
testing=adData[-inTrain,]
?train()
modFit1<-train(diagnosis ~ ., data=training, method="glm")
summary(modFit1$finalModel)
pred1<-predict(modFit1,newdata=testing)
xtab1<-table(pred1,testing$diagnosis)
confusionMatrix(xtab1)
summary(modFit1$finalModel)
preProc<-preProcess(training[,-1],method="pca",thresh=0.8)
?predict()
pred2<-predict(preProc,training[,-1],method="glm")
?train()
trainPC<-predict(preProc,training[,-1])
modelFit2<-train(training$diagnosis ~ .,method="glm",data=trainPC)
testPC<-predict(preProc,testing[,-1])
summary(modelFit2$finalModel)
confusionMatrix(testing$diagnosis,predict(modelFit2,testPC))
x<-c(.586, .166, -0.042, -0.614, 11.72)
y<-c(0.549, -0.026, -0.127, -0.751, 1.344)
?hat
hatvalues(y~x)
hatvalues(lm(y~x))
dfbetas(lm(y~x))
data(mtcars)
lm(mpg~factor(cyl)+wt, data=mtcars)
lm(mpg~factor(cyl), data=mtcars)
library(AppliedPredictiveModeling)
library(caret)
data(segmentationOriginal)
train<-segmentationOriginal[segmentationOriginal$Case==2,]
train<-segmentationOriginal[segmentationOriginal$Case=="Train",]
test<-segmentationOriginal[segmentationOriginal$Case=="Test",]
data(segmentationOriginal)
testSeg<-segmentationOriginal[segmentationOriginal$Case=="Test",]
trainSeg<-segmentationOriginal[segmentationOriginal$Case=="Train",]
set.seed(125)
modFit<-train(Class ~ .,method="rpart",data=trainSeg)
print(modFit$finalmodel)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE, main="Classification Tree")
text(modFit$FinalModel, use.n=TRUE, all=TRUE, cex=0.8)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=0.8)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
?fancyRpartPlot()
library(rpart)
fancyRpartPlot(modFit$finalModel)
?rpart.plot()
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive<-olive[,-1]
oliveFit<-train(Area~.,method="rpart", data=olive)
print(oliveFit$finalModel)
?tree()
newData=as.data.frame(t(colMeans(olive)))
predict(oliveFit,newdata=newData)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
trainSA=sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
train_SA=sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSAdat<-SAheart[trainSA,]
testSAdat<-SAheart[-trainSA,]
set.seed(13234)
?train()
?lm()
SAmodel<-lm(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSAdat, method="glm", family="binomial")
SAmodel<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSAdat, method="glm", family="binomial")
print(SAmodel$finalModel)
set.seed(13234)
SAmodel<-train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSAdat, method="glm", family="binomial")
print(SAmodel$finalModel)
predict(SAmodel,trainSAdat)
values<-trainSAdat$chd
predictTr<-predict(SAmodel,trainSAdat)
missClass=function(values,predictTr) {sum(((predictTr>0.5)*1)!=values)/length(values)}
missClass=function(values,prediction) {sum(((prediction>0.5)*1)!=values)/length(values)}
missClass(values,predictTr)
predictTest<-predict(SAmodel,testSAdat)
missClass(testSAdat$chd,predictTest)
data(vowel.train)
data(vowel.test)
vowel.train
vowel.test
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
?train
vowModel<-train(y~., data=vowel.train, method="rf", prox=TRUE)
print(vowModel$finalModel)
?varimp()
?varImp()
varImp(vowModel)
set.seed(33833)
vowModel<-train(y~., data=vowel.train, method="rf")
varImp(vowModel)
?randomForest
vowModel2<-randomForest(y~., data=vowel.train)
varImp(vowModel2)
set.seed(33833)
vowModel2<-randomForest(y~., data=vowel.train)
varImp(vowModel2)
source('~/GitHub/RepData_PeerAssessment2/WIP.R')
?rm
